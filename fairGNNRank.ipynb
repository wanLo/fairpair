{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from itertools import product\n",
    "import multiprocessing\n",
    "\n",
    "from fairpair import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('../GNNRank/')\n",
    "from src.param_parser import ArgsNamespace # just import the class, not the parser\n",
    "from src.Trainer_fair import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could install torchsort from: https://github.com/teddykoker/torchsort/releases/download/v0.1.9/torchsort-0.1.9+pt113cu117-cp311-cp311-linux_x86_64.whl\n",
    "\n",
    "â€¦or we just keep the \"raw\" scores instead of converting them to ranks to keep them differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f79e91b9390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ArgsNamespace(AllTrain=True, ERO_style='uniform', F=70, Fiedler_layer_num=5, K=20, N=350, SavePred=False, all_methods=['DIGRAC', 'ib'],\n",
    "                     alpha=1.0, baseline='syncRank', cuda=True, data_path='/home/georg/fairpair/GNNRank/data/',\n",
    "                     dataset=f'fairGNNRank_test', be_silent=True,\n",
    "                     debug=False, device=torch.device(type='cpu'), dropout=0.5, early_stopping=200, epochs=1000, eta=0.1, fill_val=0.5, hidden=8, hop=2,\n",
    "                     load_only=True, log_root='/home/georg/fairpair/GNNRank/logs/', lr=0.1, no_cuda=False, num_trials=1, optimizer='Adam', p=0.05,\n",
    "                     pretrain_epochs=50, pretrain_with='dist', regenerate_data=True, season=1990, seed=31, seeds=[10], sigma=1.0, tau=0.5, test_ratio=1,\n",
    "                     train_ratio=1, train_with='proximal_baseline', trainable_alpha=False, upset_margin=0.01, upset_margin_coeff=0, upset_ratio_coeff=1.0, weight_decay=0.0005,\n",
    "                     exposure_coeff=0.9)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FairPairGraph()\n",
    "G.generate_groups(40, 20) # same size groups\n",
    "G.assign_skills(loc=0, scale=0.86142674) # general skill distribution\n",
    "G.assign_bias(nodes=G.minority_nodes, loc=-1.43574282, scale=0.43071336) # add bias to unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampling(G, warn=False)\n",
    "sampler.apply(iter=500, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.array([group for node, group in G.nodes(data='minority')])\n",
    "adj = nx.linalg.graphmatrix.adjacency_matrix(G, weight='weight') # returns a sparse matrix\n",
    "\n",
    "trainer = Trainer(args, random_seed=10, save_name_base='test', adj=adj, groups=groups) # initialize with the given adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570e07319ff945feab0a7c11b8a69f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.6170, 0.0007, 0.6192\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.7699, 0.0000, 0.7699\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n",
      "train/exposure/combined loss: 0.6247, 0.0333, 0.7248\n"
     ]
    }
   ],
   "source": [
    "save_path_best, save_path_latest = trainer.train(model_name='ib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pred_label = trainer.predict_nn(model_name='ib', model_path=save_path_best, A=None, GNN_variant='proximal_baseline')\n",
    "ranking = {key: 1-score[0] for key, score in enumerate(score.cpu().detach().numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error 0.27756810996904957\n",
      "Majority error 0.29423872742534846\n",
      "Minority error 0.3373318282734238\n",
      "Majority exposure 0.3429486601082835\n",
      "Minority exposure 0.21160297442439538\n"
     ]
    }
   ],
   "source": [
    "ranking_as_ranks = scores_to_rank(ranking, invert=False)\n",
    "base_scores = [skill for node, skill in G.nodes(data='skill')]\n",
    "all_nodes = list(range(40))\n",
    "majority_nodes = list(range(20))\n",
    "minority_nodes = list(range(20,40))\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=all_nodes, complementary_nodes=[])\n",
    "print('Overall error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=majority_nodes, complementary_nodes=minority_nodes)\n",
    "print('Majority error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=minority_nodes, complementary_nodes=majority_nodes)\n",
    "print('Minority error', tau)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=majority_nodes)\n",
    "print('Majority exposure', exp)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=minority_nodes)\n",
    "print('Minority exposure', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 41])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.2308,  -1.5952,  -0.7228,   1.0095,  -0.3774,   2.2280,   0.0453,\n",
       "         -0.1164,  -0.7551,   2.2361,   1.9317,   0.1265,   1.9759,   0.2779,\n",
       "         -0.3362,   0.6641,  -0.3251,   0.0656,   0.7208,  -0.7944,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000, -10.0000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.features[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error 0.26621178675828944\n",
      "Majority error 0.28049463306296935\n",
      "Minority error 0.32407783610015917\n",
      "Majority exposure 0.34236361501154333\n",
      "Minority exposure 0.21218801952113564\n"
     ]
    }
   ],
   "source": [
    "ranker = RankRecovery(G)\n",
    "scores, nodes = ranker.apply()\n",
    "ranking_as_ranks = scores_to_rank(scores, invert=False)\n",
    "base_scores = [skill for node, skill in G.nodes(data='skill')]\n",
    "all_nodes = list(range(40))\n",
    "majority_nodes = list(range(20))\n",
    "minority_nodes = list(range(20,40))\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=all_nodes, complementary_nodes=[])\n",
    "print('Overall error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=majority_nodes, complementary_nodes=minority_nodes)\n",
    "print('Majority error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=minority_nodes, complementary_nodes=majority_nodes)\n",
    "print('Minority error', tau)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=majority_nodes)\n",
    "print('Majority exposure', exp)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=minority_nodes)\n",
    "print('Minority exposure', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNRank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
